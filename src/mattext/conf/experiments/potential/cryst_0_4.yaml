# @package _global_
model:
  representation: crystal_llm_rep
  alpha: 0.4
  logging:
    wandb_project: potential_lj
  special_num_token: False

  finetune:
    model_name: potential_0_4
    context_length: 512
    training_arguments:
      per_device_train_batch_size: 128
    path:
      pretrained_checkpoint: /home/so87pot/n0w0f/mattext_ckpt/santiago_ckpt_normal/crystal_llm_rep_pt_2m/checkpoint-393000
