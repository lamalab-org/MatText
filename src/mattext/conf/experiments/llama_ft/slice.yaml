# @package _global_
model:
  representation: slice
  logging:
    wandb_project: lama_2

  finetune:
    model_name: lama_2
    # context_length: 512
    # training_arguments:
    #   per_device_train_batch_size: 64
    # path:
    #   pretrained_checkpoint: "/work/so87pot/mattext/megaloop/checkpoints/checkpoints/slice_pt_30k_wes/checkpoint-46000"
