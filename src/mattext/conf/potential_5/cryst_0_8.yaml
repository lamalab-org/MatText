# @package _global_
model:
  representation: zmatrix
  alpha: 0.8
  logging:
    wandb_project: potential_lj_zmatrix
  special_num_token: False

  finetune:
    model_name: zmatrix_potential_0_8
    context_length: 512
    training_arguments:
      per_device_train_batch_size: 128
    path:
      pretrained_checkpoint: /work/so87pot/mattext/megaloop/checkpoints/checkpoints/zmatrix_pt_300k_zmatrix/checkpoint-85000
