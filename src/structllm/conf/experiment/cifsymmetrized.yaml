# @package _global_

defaults:
  - override /model: pretrain_template

model:
  representation: cif_symmetrized
  pretrain.context_length: 1024
  pretrain.training_arguments.per_device_train_batch_size: 16