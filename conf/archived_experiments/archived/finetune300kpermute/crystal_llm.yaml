# @package _global_
model:
  representation: crystal_llm_rep
  logging:
    wandb_project: permute_300k_7seed
  finetune:
    model_name: ft_300k_mb_small
    context_length: 512
    training_arguments:
      per_device_train_batch_size: 64
    path:
      pretrained_checkpoint: /work/so87pot/mattext/megaloop/pretrain300k/crystal_llm_rep_pt_300/checkpoint-57000
