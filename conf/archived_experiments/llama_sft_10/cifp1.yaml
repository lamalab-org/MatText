# @package _global_
model:
  representation: cif_p1
  logging:
    wandb_project: llama3_8_gen
  finetune:
    path:
      pretrained_checkpoint: "meta-llama/Meta-Llama-3-8B"
    model_name: llama3_8_gen
    # context_length: 1024
    training_arguments:
      per_device_train_batch_size: 16
    # path:
    #   pretrained_checkpoint: "/work/so87pot/mattext/megaloop/checkpoints/checkpoints/cif_p1_pt_30k_wes/checkpoint-46000"
