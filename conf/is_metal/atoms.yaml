# @package _global_
model:
  representation: atom_sequences
  dataset: "bandgap"
  dataset_type: matbench
  special_num_token: False
  checkpoint: n0w0f/MatText-atom-seq-2m
  logging:
    wandb_project: revision-bg

  finetune:
    model_name: revision-bg
    context_length: 32
    training_arguments:
      per_device_train_batch_size: 1024
    path:
      pretrained_checkpoint: n0w0f/MatText-atom-seq-2m

    